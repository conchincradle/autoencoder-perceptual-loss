{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Qk3OfCXetNCysoKi7APzLlmv9Q0dybhQ",
      "authorship_tag": "ABX9TyOGPBxY+WlIF3ar+2pooQE1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/conchincradle/autoencoder_perceptual_loss/blob/main/autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "J8Gcuajm56ar",
        "outputId": "06cd31d6-873d-4266-b885-20d0291859f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'imagenet-autoencoder'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Total 124 (delta 0), reused 0 (delta 0), pack-reused 124\u001b[K\n",
            "Receiving objects: 100% (124/124), 1.09 MiB | 23.80 MiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r ./imagenet-autoencoder/requirements.txt (line 1)) (1.11.0+cu113)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r ./imagenet-autoencoder/requirements.txt (line 2)) (7.1.2)\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r ./imagenet-autoencoder/requirements.txt (line 4)) (1.21.6)\n",
            "Collecting argparse\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r ./imagenet-autoencoder/requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r ./imagenet-autoencoder/requirements.txt (line 7)) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r ./imagenet-autoencoder/requirements.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r ./imagenet-autoencoder/requirements.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r ./imagenet-autoencoder/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r ./imagenet-autoencoder/requirements.txt (line 6)) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r ./imagenet-autoencoder/requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->-r ./imagenet-autoencoder/requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->-r ./imagenet-autoencoder/requirements.txt (line 7)) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r ./imagenet-autoencoder/requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r ./imagenet-autoencoder/requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r ./imagenet-autoencoder/requirements.txt (line 7)) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r ./imagenet-autoencoder/requirements.txt (line 7)) (2.10)\n",
            "Installing collected packages: loguru, argparse\n",
            "Successfully installed argparse-1.4.0 loguru-0.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!git clone https://github.com/Horizon2333/imagenet-autoencoder\n",
        "\n",
        "!pip install -r ./imagenet-autoencoder/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1WwJiQ1kBcNCZ37F6PJ_0bIL0ZeU3_sV8 --"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuV8ZVrP8lom",
        "outputId": "a76e4c74-5c13-4a7a-db7e-d62c4ee5f9bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WwJiQ1kBcNCZ37F6PJ_0bIL0ZeU3_sV8\n",
            "To: /content/imagenet-vgg16.pth\n",
            "100% 255M/255M [00:02<00:00, 127MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "shutil.move(\"/content/imagenet-vgg16.pth\",\"/content/imagenet-autoencoder\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iRp_ltd0-4lq",
        "outputId": "b41b1abf-5dc2-4b8c-e4cf-ea12c4030101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/imagenet-autoencoder/imagenet-vgg16.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "os.chdir(\"imagenet-autoencoder\")\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSqOjuW-AINm",
        "outputId": "eff7900d-4dd9-4a34-f7f9-ee4e40981c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  imagenet-autoencoder  real1.jpg\tsample_data\n",
            "dataloader.py  imagenet-vgg16.pth  requirements.txt  train.py\n",
            "eval.py        models\t\t   run\t\t     utils.py\n",
            "figs\t       README.md\t   tools\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "print(torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umN3Njq_BrSw",
        "outputId": "dae92221-8038-48b0-f81a-854cb412f598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# python tools/encode.py --arch {model architecture} --resume {checkpoint path} --img_path {image path}\n",
        "# For example\n",
        "\n",
        "\n",
        "!python tools/encode.py --arch vgg16 --resume imagenet-vgg16.pth --img_path figs/reconstruction.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zts3Qgs6cAn",
        "outputId": "ae511935-03c1-493d-bb5f-990024aefa55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 670, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 583, in module_from_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1043, in create_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
            "RuntimeError: KeyboardInterrupt: \n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"tools/encode.py\", line 7, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/__init__.py\", line 199, in <module>\n",
            "    from torch._C import *  # noqa: F403\n",
            "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "import argparse\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"./\")\n",
        "\n",
        "import utils\n",
        "import models.builer as builder\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "def get_args():\n",
        "    # parse the args\n",
        "    print('=> parse the args ...')\n",
        "    parser = argparse.ArgumentParser(description='Encoder for auto encoder')\n",
        "    parser.add_argument('--arch', default='vgg16', type=str, \n",
        "                        help='backbone architechture')\n",
        "    parser.add_argument('--resume', type=str)\n",
        "    parser.add_argument('--img_path',type=str)              \n",
        "    \n",
        "    args = parser.parse_args([\"--arch\",\"vgg16\",'--resume',\"imagenet-vgg16.pth\",'--img_path',\"figs/real1.jpg\"])\n",
        "    \n",
        "    \n",
        "\n",
        "    args.parallel = 0\n",
        "    args.batch_size = 1\n",
        "    args.workers = 0\n",
        "\n",
        "    print(args)\n",
        "\n",
        "    return args\n",
        "\n",
        "def encode(model, img):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        code = model.module.encoder(img).cpu().numpy()\n",
        "\n",
        "    return code\n",
        "\n",
        "def main(args):\n",
        "    print('=> torch version : {}'.format(torch.__version__))\n",
        "\n",
        "    utils.init_seeds(1, cuda_deterministic=False)\n",
        "\n",
        "    print('=> modeling the network ...')\n",
        "    model = builder.BuildAutoEncoder(args)     \n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print('=> num of params: {} ({}M)'.format(total_params, int(total_params * 4 / (1024*1024))))\n",
        "\n",
        "    print('=> loading pth from {} ...'.format(args.resume))\n",
        "    utils.load_dict(args.resume, model)\n",
        "    \n",
        "    trans = transforms.Compose([\n",
        "                    transforms.Resize(256),                   \n",
        "                    transforms.CenterCrop(224),\n",
        "                    transforms.ToTensor()\n",
        "                  ])\n",
        "\n",
        "    img = Image.open(args.img_path).convert(\"RGB\")\n",
        "\n",
        "    img = trans(img).unsqueeze(0).cuda()\n",
        "\n",
        "    model.eval()\n",
        "    global code\n",
        "\n",
        "\n",
        "    code = encode(model, img)\n",
        "    print(code[0][0])\n",
        "    \n",
        "\n",
        "    # To do : any other postprocessing\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "\n",
        "    args = get_args()\n",
        "\n",
        "    main(args)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdW6UaEZHJ8W",
        "outputId": "ac3d321a-31e8-4f8f-ebc0-e59a27eb132d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> parse the args ...\n",
            "Namespace(arch='vgg16', batch_size=1, img_path='figs/real1.jpg', parallel=0, resume='imagenet-vgg16.pth', workers=0)\n",
            "=> torch version : 1.11.0+cu113\n",
            "=> modeling the network ...\n",
            "=> num of params: 31888451 (121M)\n",
            "=> loading pth from imagenet-vgg16.pth ...\n",
            "[[0.10059284 0.08181164 0.05440877 0.04786503 0.1139784  0.09746966\n",
            "  0.06345142]\n",
            " [0.05704408 0.06076542 0.05314697 0.0485983  0.08766764 0.07002585\n",
            "  0.07253406]\n",
            " [0.05509628 0.06743823 0.05489914 0.07119349 0.09968959 0.06315568\n",
            "  0.07919201]\n",
            " [0.07877008 0.09272821 0.0779055  0.06059049 0.09519731 0.07806238\n",
            "  0.06707303]\n",
            " [0.09977935 0.06114728 0.06988992 0.04920468 0.10277557 0.0697617\n",
            "  0.07723462]\n",
            " [0.09304125 0.06410365 0.06264398 0.05646518 0.08988865 0.04452971\n",
            "  0.0815033 ]\n",
            " [0.06098513 0.05854816 0.04899107 0.04776639 0.09046818 0.05839682\n",
            "  0.03120703]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#wet2 = 2*(wet1-dry1)+code\n",
        "3#newcode =code.copy()\n"
      ],
      "metadata": {
        "id": "7pw4ri-3VcUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cfa7a76-0cab-4cc3-abfe-dc3c5e739555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "import argparse\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"./\")\n",
        "\n",
        "import utils\n",
        "import models.builer as builder\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "def get_args():\n",
        "    # parse the args\n",
        "    print('=> parse the args ...')\n",
        "    parser = argparse.ArgumentParser(description='Trainer for auto encoder')\n",
        "    parser.add_argument('--arch', default='vgg16', type=str, \n",
        "                        help='backbone architechture')\n",
        "    parser.add_argument('--resume', type=str)      \n",
        "    \n",
        "    args = parser.parse_args([\"--arch\",\"vgg16\",'--resume',\"imagenet-vgg16.pth\"])\n",
        "\n",
        "    args.parallel = 0\n",
        "    args.batch_size = 1\n",
        "    args.workers = 0\n",
        "\n",
        "    return args\n",
        "\n",
        "def random_sample(arch):\n",
        "\n",
        "    if arch in [\"vgg11\", \"vgg13\", \"vgg16\", \"vgg19\", \"resnet18\", \"resnet34\"]:\n",
        "        return torch.randn((1,512,7,7))\n",
        "    elif arch in [\"resnet50\", \"resnet101\", \"resnet152\"]:\n",
        "        return torch.randn((1,2048,7,7))\n",
        "    else:\n",
        "        raise NotImplementedError(\"Do not have implemention except VGG and ResNet\")\n",
        "\n",
        "def main(args):\n",
        "    print('=> torch version : {}'.format(torch.__version__))\n",
        "\n",
        "    utils.init_seeds(1, cuda_deterministic=False)\n",
        "\n",
        "    print('=> modeling the network ...')\n",
        "    model = builder.BuildAutoEncoder(args)     \n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print('=> num of params: {} ({}M)'.format(total_params, int(total_params * 4 / (1024*1024))))\n",
        "\n",
        "    print('=> loading pth from {} ...'.format(args.resume))\n",
        "    utils.load_dict(args.resume, model)\n",
        "\n",
        "    trans = transforms.ToPILImage()\n",
        "\n",
        "   \n",
        "\n",
        "    model.eval()\n",
        "    print('=> Generating ...')\n",
        "    with torch.no_grad():\n",
        "        for i in range(512):\n",
        "            newcode = code.copy()\n",
        "            newcode += np.random.normal(0,0.001*i,512*7*7).reshape((512,7,7))\n",
        "            #wet2 = 0.1*i*(wet1-dry1)+code\n",
        "            input = torch.Tensor(newcode).cuda()\n",
        "            \n",
        "\n",
        "            output = model.module.decoder(input)\n",
        "            \n",
        "            output = trans(output.squeeze().cpu())\n",
        "            filename  = \"figs/0g\"+str(i)+\".jpg\"\n",
        "            output.save(filename)\n",
        "    print(\"Completed\")\n",
        "\n",
        "            \n",
        "\n",
        "   \n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    args = get_args()\n",
        "\n",
        "    main(args)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOpOfmRsQ8AW",
        "outputId": "c35b5548-c466-4986-e76c-8c6082cedf65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> parse the args ...\n",
            "=> torch version : 1.11.0+cu113\n",
            "=> modeling the network ...\n",
            "=> num of params: 31888451 (121M)\n",
            "=> loading pth from imagenet-vgg16.pth ...\n",
            "=> Generating ...\n",
            "Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bKItM_mIQcTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, tarfile\n",
        " \n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "def make_targz_one_by_one(output_filename, source_dir):\n",
        "  tar = tarfile.open(output_filename,\"w\")\n",
        "  for root,dir_name,files_list in os.walk(source_dir):\n",
        "    for file in files_list:\n",
        "      pathfile = os.path.join(root, file)\n",
        "      tar.add(pathfile)\n",
        "  tar.close()\n",
        " \n",
        "  files.download(output_filename)\n",
        " \n",
        " \n",
        "make_targz_one_by_one('res.tar', '/content/imagenet-autoencoder/figs')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "2DOjhqgT_rFE",
        "outputId": "23892d30-1275-4e00-d80b-ef15bfbd5c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3eb25d89-9816-4adf-96c9-6139df08d2d2\", \"res.tar\", 10137600)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "2HnVoopoNjQW",
        "outputId": "dc12ca4f-96a5-44bf-ae1d-9666cb0b748a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-e257dca5d022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewcode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'newcode' is not defined"
          ]
        }
      ]
    }
  ]
}